**************QUERY***************: 
 
You are a highly skilled academic AI assistant. Your role is to respond to user queries with structured,
clear, and well-organized answers, maintaining an academic tone and focusing on relevance and clarity.

User Query: **Question**: List all contributions of the paper. These contributions are always organized and listed with a head sentence like **our contributions are as follows**. For each contribution, output the **original representation** and use a few words to summarize it.

Guidance:
Research papers typically contain key components, including the problem definition, challenges,
contributions, solutions, and experimental results. These components are generally organized as follows:
- **Problem Definition, Challenges, and Contributions**: Usually found within the first few sections.
- **Solutions**: Typically located in the main body of the paper.
- **Experiment Results**: Usually appear toward the end in sections titled "Experiments" or "Empirical Studies."

The content is retrieved in annotated chunks, marked with **SECTION_X** (indicating the specific section)
or **POS_0.XX** (indicating the position within the paper, calculated as current page/total pages).
Use these annotations to identify and focus on the sections most relevant to the userâ€™s query,
ensuring a precise and targeted response.
                             **************MEMORY**************: 
 **SECTION_1**: forecasting results. The e ciency of these networks can be explained by the recurrent connections that allow the network to access the entire history of previous time series values. Alternatively one might employ a convolutional neural network with multiple layers of dilated convolutions 27 . The dilated convolutions, in which the lter is applied by skipping certain elements in the input, allow for the receptive eld of the
**SECTION_paper_meta**: Keywords: Convolutional neural network, nancial time series, forecasting, deep learning, multivariate time series
**SECTION_1**: 16 or time series classi cation 26 . The CNN consists of a sequence of convolutional layers, the output of which is connected only to local regions in the input. This is achieved by sliding a lter, or weight matrix, over the input and at each point computing the dot product between the two i.e. a convolution between the input and lter . This structure allows the model to learn lters that are able to recognize speci c patterns in
**SECTION_1**: series, by discarding in each subsequent layer the noise and extracting only the meaningful patterns, in this way bearing similarities to neural networks which use wavelet transformed time series i.e. a split in highand low frequency components as input, see e.g. 1 , 17 . Currently, recurrent neural networks RNNs , and in particular the long short term memory unit LSTM 12 , 5 , are the state of the art in time series forecasting, see also 14 and in particular 7 for nancial
**SECTION_paper_meta**: interest rate and several exchange rates and extensively compare it to the performance of the well known autoregressive model and a long short term memory network. We show that a convolutional network is well suited for regression type problems and is able to e ectively learn dependencies in and between the series without the need for long historical time series, is a time e cient and easy to implement alternative to recurrent type networks and tends to outperform linear and recurrent models.
**SECTION_1**: reducing the noise, since it allows one to exploit the correlations in between related time series. As a whole, we show that convolutional networks can be a much simpler and easier to train alternative to recurrent networks while achieving an at least as good or better accuracy on non linear, noisy forecasting tasks.
**SECTION_1**: dependencies in the data as well as have a high noise resistance. Traditional autoregressive models such as VAR and ARMA 9 fail to capture non linear patterns. Feedforward neural networks have been a popular way of learning the dependencies in the data as these allow to learn non linearities without the need of Dipartimento di Matematica, Universit a di Bologna, Bologna, Italy. e mail: anastasia.borovykh2 unibo.it
**SECTION_1**: specifying a particular model form in advance, see 28 or 4 . Hybrid approaches using neural networks and econometric models have also been proposed, e.g. 29 . One downside of classical feedforward neural networks is that a large sample size of data is required to obtain a stable forecasting result. The main focus of this paper is on multivariate time series forecasting, speci cally nancial time series.
**SECTION_1**: time series. Similar to 23 it makes use of the dilated convolutions, however these convolutions are applied with parametrized skip connections 11 from both the input time series as well as the time series we condition on, in this way learning long and short term interdependencies in an e cient manner. Furthermore, the gated activation function from the original WaveNet model is replaced by a recti ed linear unit ReLU , simplifying the model and reducing the training time.
**SECTION_1**: 1 Introduction Forecasting nancial time series using past observations has been a topic of signi cant interest for obvious reasons. It is well known that while temporal relationships in the data exist, they are di cult to analyze and predict accurately due to the non linear trends, heavy tails and noise present in the series 6 . In developing models for forecasting nancial data it is desirable that these will be both able to learn non linear
**SECTION_paper_meta**: is performed by applying multiple convolutional lters in parallel to separate time series which allows for the fast processing of data and the exploitation of the correlation structure between the multivariate time series. We test and analyze the performance of the convolutional network both unconditionally as well as conditionally for nancial time series forecasting using the S P500, the volatility index, the CBOE
**SECTION_1**: of history. The advantage of the CNN over the recurrent type network is that due to the convolutional structure of the network, the number of trainable weights is small, resulting in a much more e cient training and predicting. Motivated by 25 in which the authors compare the performance of the PixelCNN to the PixelRNN 24 , a network used for image generation, in this paper, we aim to investigate the performance of the
**SECTION_1**: convolutional neural network compared to that of autoregressive and recurrent models on forecasting noisy, nancial time series. The CNN we employ is a network inspired by the convolutional WaveNet model from 23 rst developed for audio forecasting, whose structure we simplify and optimize for multivariate time series forecasting. Our network focusses on learning long term relationships in and between multivariate, noisy
**SECTION_1**: works and tends to outperform the linear and recurrent models. Lastly, we show using examples on arti cial time series as well as the S P500, VIX, CBOE interest rate and ve exchange rates that the e cient way of conditioning in the WaveNet model enables one to extract temporal relationships in between time series improving the forecast, while at the same time limiting the requirement for a long historical price series and
**SECTION_1**: using the notion of conditioning to reduce the noisiness in short duration series. E ectively, we use multiple nancial time series as input in a neural network, thus conditioning the forecast of a time series on both its own history as well as that of multiple other time series. Training a model on multiple stock series allows the network to exploit the correlation structure between these series so that the network can learn the market
**SECTION_1**: In particular, we forecast time series conditional on other, related series. Financial time series are known to both have a high noise component as well as to be of limited duration even when available, the use of long histories of stock prices can be di cult due to the changing nancial environment. At the same time, many di erent, but strongly correlated nancial time series exist. Here, we aim to exploit multivariate forecasting
**SECTION_1**: the input data. Recent advances in CNNs for time series forecasting include 20 where the authors propose an undecimated convolutional network for time series modelling based on the undecimated wavelet transform and 3 in which the authors propose to use an autoregressive type weighting system for forecasting nancial time series, where the weights are allowed to be data dependent by learning them through a CNN. In general
**SECTION_1**: This paper consists of several main contributions. First of all, we present a CNN inspired by the WaveNet model, with a structure that is simpli ed and optimized for time series forecasting, i.e. using a ReLU activation and a novel and more optimal way of conditioning with parametrized skip connections. Second, knowing the strong performance of CNNs on classi cation problems, our work is to the best of our knowledge the
**SECTION_1**: dynamics in shorter sequences of data. As shown by e.g. 30 for classi cation, using multiple conditional time series as inputs can improve both the robustness and forecast quality of the model by learning long term temporal dependencies in between series. A convolutional neural network CNNs , see 18 , is a biologically inspired type of deep neural network DNN that has recently gained popularity due to its success in classi cation problems e.g. image recognition
**SECTION_1**: literature on nancial time series forecasting with convolutional architectures is still scarce, as these types of networks are much more commonly applied in classi cation problems. Intuitively, the idea of applying CNNs to time series forecasting would be to learn lters that represent certain repeating patterns in the series and use these to forecast the future values. Due to the layered structure of CNNs, they might work well on noisy
**SECTION_1**: rst to show that they can be applied successfully to forecasting nancial time series of limited length. By conducting an extensive analysis of the WaveNet model and comparing the performance to that of an LSTM, the current state of the art in forecasting, and an autoregressive model popular in econometrics our paper shows that the WaveNet model is a time e cient and easy to implement alternative to recurrent type net
**SECTION_paper_meta**: Conditional time series forecasting with convolutional neural networks Anastasia Borovykh Sander Bohte Cornelis W. Oosterlee This version: September 18, 2018 Abstract We present a method for conditional time series forecasting based on an adaptation of the recent deep convolutional WaveNet architecture. The proposed network contains stacks of dilated convolutions that allow it to access a broad range of history when forecasting, a ReLU activation function and conditioning
**SECTION_1**: network to grow exponentially, hereby allowing the network to, similar to the RNN, access a broad range 2
**SECTION_1**: Centrum Wiskunde Informatica, Amsterdam, The Netherlands. e mail:s.m.bohte cwi.nl Centrum Wiskunde Informatica, Amsterdam, The Netherlands. e mail: c.w.oosterlee cwi.nl Delft University of Technology, Delft, The Netherlands 1 arXiv:1703.04691v5 stat.ML 17 Sep 2018
