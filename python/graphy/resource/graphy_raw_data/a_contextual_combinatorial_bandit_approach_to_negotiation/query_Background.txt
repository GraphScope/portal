**************QUERY***************: 
 
You are a highly skilled academic AI assistant. Your role is to respond to user queries with structured,
clear, and well-organized answers, maintaining an academic tone and focusing on relevance and clarity.

User Query: **Question**: Please describe the problem studied in this paper, why the problem is worth studying, and what are the issues of existing solutions to this problem.

Guidance:
Research papers typically contain key components, including the problem definition, challenges,
contributions, solutions, and experimental results. These components are generally organized as follows:
- **Problem Definition, Challenges, and Contributions**: Usually found within the first few sections.
- **Solutions**: Typically located in the main body of the paper.
- **Experiment Results**: Usually appear toward the end in sections titled "Experiments" or "Empirical Studies."

The content is retrieved in annotated chunks, marked with **SECTION_X** (indicating the specific section)
or **POS_0.XX** (indicating the position within the paper, calculated as current page/total pages).
Use these annotations to identify and focus on the sections most relevant to the userâ€™s query,
ensuring a precise and targeted response.
                             **************MEMORY**************: 
 **SECTION_1**: b presents a resource allocation task. Items in green are proposed for allocation to negotiator a, while those in red are suggested for assignment to negotiator g. Lastly, c portrays a multi issue negotiation task involving two distinct issues, each offering several value choices. Negotiators a and g aim to agree on the values of these two issues. negotiation, while a super arm signifies a bid composed of multiple items. The term acceptance is specifically des
**SECTION_1**: Learning, Vienna, Austria. PMLR 235, 2024. Copyright 2024 by the author s . counterpart. These negotiations can vary in form, and Figure 1 illustrates three representative negotiation problems: trading, resource allocation, and multi issue negotiation. As negotiation experiences accumulate, an agent should continuously improve its negotiation ability. However, effectively exploiting past experiences in subsequent negotiations is challenging in the following aspects.
**SECTION_abstract**: demonstrate the superiority of our approach.
**SECTION_1**: 1. Introduction Negotiation serves as a fundamental process that underpins interaction among diverse agents across a wide spectrum of domains, ranging from diplomacy Paquette et al., 2019; FAIR et al., 2022 and resource allocation Lewis et al., 2017; Cao et al., 2018 to trading Bagga et al., 2020 . In these scenarios, an agent, represented as negotiator a, engages in negotiation with various counterparts g, with its state evolving. At each time step, negotiator a proposes a
**SECTION_1**: Exploration exploitation dilemma: As counterparts vary and the agent s state evolves, over exploiting historical data may result in sub optimal performance, while excessive exploration may make the counterpart lose patience. Existing works on negotiation Lewis et al., 2017; Liu Zheng, 2020; Sengupta et al., 2022 tend to neglect exploration, primarily focusing on exploitation, or simply explore by UCT Buron et al., 2019 , without considering observable
**SECTION_1**: bid and receives feedback indicating whether the counterpart g accepts or rejects the proposal. Successful acceptance leads to a deal, while rejection leads to termination or further negotiation, possibly with counter proposals from the 1State Key Laboratory of General Artificial Intelligence, BIGAI, Beijing, China 2Peking University. Correspondence to: Siyuan Qi syqi bigai.ai . Proceedings of the 41 st International Conference on Machine
**SECTION_1**: regression Schulz et al., 2018; Vakili et al., 2023 . Under mild assumptions, NegUCB s regret upper bound is guaranteed to be sub linear with respect to the number of negotiation steps and independent of the bid cardinality, distinguishing itself from existing works on either semi bandit or full bandit feedback. In summary, this paper makes three major contributions. First, we provide a comprehensive formulation for diverse types of negotiation problems in 3.1. Second, we pro
**SECTION_paper_meta**: A Contextual Combinatorial Bandit Approach to Negotiation Yexin Li 1 Zhancun Mu 2 Siyuan Qi 1
**SECTION_1**: low dimensional continuous action spaces. Partial observations: The profiles of counterparts, including their preferences and desires, cannot be fully observed. Relying solely on observable contexts for negotiation can be ineffective. Complicated acceptance functions: Inferring the likelihood of the counterpart accepting a bid remains challenging, even when their hidden states are known. In this paper, we formulate negotiation problems using con
**SECTION_1**: pose NegUCB to learn negotiation strategies, effectively addressing the prevalent challenges in negotiation in 3.2. Lastly, we provide theoretical insights in 3.3 and conduct experiments on representative negotiation tasks in 4, highlighting the advantages and effectiveness of our method.
**SECTION_1**: textual combinatorial multi armed bandits Li et al., 2010; Chen et al., 2013; Qin et al., 2014; Wen et al., 2015; Chen et al., 2018; Agarwal et al., 2021; Nie et al., 2022 to address the exploration exploitation dilemma and handle the large action spaces of combinatorial cardinality. Although negotiation involves a series of actions, unlike in reinforcement learning, where actions may lead to state transitions, bid actions in negotiation do not inherently trigger such transi
**SECTION_1**: A Contextual Combinatorial Bandit Approach to Negotiation Figure 1. Three typical types of negotiation. Negotiator a is represented with the same icon but in varying colors, indicating the same agent whose state evolves. Negotiator g is depicted with distinct icons and colors, meaning different counterparts. a illustrates a trading task, where items in Red signify those that negotiator a gives to g, while items in Green indicate those that counterpart g gives to a.
**SECTION_1**: tions. Agents accumulate knowledge about their counterparts through interactions. Consequently, the bandit based formulation is well suited for negotiation problems. In our formulation, an arm denotes an item involved in the 1 arXiv:2407.00567v1 cs.AI 30 Jun 2024
**SECTION_abstract**: dilemma, and the combinatorial nature handles large action spaces. Building upon this formulation, we introduce NegUCB, a novel method that also handles common issues such as partial observations and complex reward functions in negotiation. NegUCB is contextual and tailored for full bandit feedback without constraints on the reward functions. Under mild assumptions, it ensures a sub linear regret upper bound. Experiments conducted on three negotiation tasks
**SECTION_1**: within the bid remains inaccessible, and only an aggregate acceptance value for the entire bid is available. Otherwise, the feedback is referred to as semi bandit. Presently, most works Qin et al., 2014; Wen et al., 2015; Chen et al., 2018; Hwang et al., 2023 on combinatorial bandits rely on semibandit feedback. Although there are works Rejwan Mansour, 2020; Agarwal et al., 2021; Nie et al., 2022; Fourati et al., 2023 that consider full bandit feedback, they are
**SECTION_abstract**: Abstract Learning effective negotiation strategies poses two key challenges: the exploration exploitation dilemma and dealing with large action spaces. However, there is an absence of learning based approaches that effectively address these challenges in negotiation. This paper introduces a comprehensive formulation to tackle various negotiation problems. Our approach leverages contextual combinatorial multi armed bandits, with the bandits resolving the exploration exploitation
**SECTION_1**: ignated to represent the reward, with a value of 1 assigned when the counterpart accepts the bid and 0 assigned in the case of rejection. Consequently, our primary objective is the systematic selection of super arms to gain a comprehensive understanding of the expected acceptance of each super arm while ensuring a substantial cumulative benefit in the long run. This formulation involves full bandit feedback, where information regarding the acceptance of individual items
**SECTION_1**: contexts. Large action spaces: Consider a trading task in which our negotiator possesses items V1 while the counterpart holds items V2. The potential bid can be any subset of the union V V1 V2, resulting in 2 V possible choices. Some studies Cao et al., 2018; Bakker et al., 2019; Bagga et al., 2020 employ reinforcement learning to acquire negotiation strategies, but they primarily focus on tasks involving action spaces limited to a few hundred discrete actions or
**SECTION_1**: non contextual and often subject to specific constraints. Building upon the above formulation, we propose a contextual algorithm for full bandit feedback, named Negotiation UCB NegUCB , to learn negotiation strategies and adeptly address the exploitation exploration dilemma and the challenge of large action spaces. Moreover, NegUCB incorporates hidden states to tackle the issue of partial observations and handles diverse acceptance functions through kernel
