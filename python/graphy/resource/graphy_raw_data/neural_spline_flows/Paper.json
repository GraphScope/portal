{
    "data": {
        "id": "neural2019durkan",
        "published": "2019-12-03T01:26:59+00:00",
        "year": 2019,
        "month": 12,
        "title": "Neural Spline Flows",
        "authors": [
            "Durkan, Conor, Artur Bekasov, Iain Murray, and George Papamakarios. "
        ],
        "summary": "\u2026 , we refer to the resulting class of normalizing flows as rational-quadratic neural spline flows  (RQ-NSF), \u2026 [22], and the universal approximation capabilities of neural networks in general. \u2026",
        "journal_ref": "Advances in neural information processing systems, 2019",
        "doi": "",
        "primary_category": "",
        "categories": "",
        "bib": "@article{durkan2019neural,\\n  title={Neural spline flows},\\n  author={Durkan, Conor and Bekasov, Artur and Murray, Iain and Papamakarios, George},\\n  journal={Advances in neural information processing systems},\\n  volume={32},\\n  year={2019}\\n}",
        "reference": [
            "",
            "[13] M. Germain, K. Gregor, I. Murray, and H. Larochelle. MADE: Masked autoencoder for distribution estimation. International Conference on Machine Learning , 2015.",
            "[52] E. Snelson, C. E. Rasmussen, and Z. Ghahramani. Warped Gaussian processes. Advances in Neural Information Processing Systems , 2004.",
            "[47] D. J. Rezende and F. Viola. Taming VAEs. arXiv:1810.00597 , 2018.",
            "Table 6: Validation log likelihood (in nats) for UCI datasets and BSDS300, with error bars corre- sponding to two standard deviations.",
            "[22] C.-W. Huang, D. Krueger, A. Lacoste, and A. Courville. Neural autoregressive \ufb02ows. International Conference on Machine Learning , 2018.",
            "[42] G. Papamakarios. Preprocessed datasets for MAF experiments, 2018. URL https://doi.org/10.5281/ zenodo.1161203 .",
            "[16] W. Grathwohl, R. T. Q. Chen, J. Bettencourt, I. Sutskever, and D. K. Duvenaud. FFJORD: Free-form continuous dynamics for scalable reversible generative models. International Conference on Learning Representations , 2018.",
            "[20] J. Ho, X. Chen, A. Srinivas, Y. Duan, and P. Abbeel. Flow++: Improving \ufb02ow-based generative models with variational dequantization and architecture design. International Conference on Machine Learning , 2019.",
            "[53] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov. Dropout: A simple way to prevent neural networks from over\ufb01tting. The Journal of Machine Learning Research , 15(1):1929\u20131958, 2014.",
            "[60] A. van den Oord, N. Kalchbrenner, and K. Kavukcuoglu. Pixel recurrent neural networks. International Conference on Machine Learning , 2016.",
            "[44] G. Papamakarios, D. C. Sterratt, and I. Murray. Sequential neural likelihood: Fast likelihood-free inference with autoregressive \ufb02ows. International Conference on Arti\ufb01cial Intelligence and Statistics , 2019.",
            "C Additional experimental results C.1 Af\ufb01ne coupling transforms for 2D datasets Densities \ufb01t by a model with two af\ufb01ne coupling layers on synthetic two-dimensional datasets are shown in \ufb01g. 4.",
            "[4] S. S. Chen and R. A. Gopinath. Gaussianization. Advances in Neural Information Processing Systems , 2001.",
            "[29] D. P. Kingma and M. Welling. Auto-encoding variational Bayes. International Conference on Learning Representations , 2014.",
            "[2] Y. Burda, R. B. Grosse, and R. Salakhutdinov. Importance weighted autoencoders. International Conference on Learning Representations , 2016.",
            "C.1 Af\ufb01ne coupling transforms for 2D datasets Densities \ufb01t by a model with two af\ufb01ne coupling layers on synthetic two-dimensional datasets are shown in \ufb01g. 4.",
            "[41] J. B. Oliva, A. Dubey, M. Zaheer, B. P\u00f3czos, R. Salakhutdinov, E. P. Xing, and J. Schneider. Transformation autoregressive networks. International Conference on Machine Learning , 2018.",
            "[19] K. He, X. Zhang, S. Ren, and J. Sun. Identity mappings in deep residual networks. European Conference on Computer Vision , 2016.",
            "[58] A. van den Oord, S. Dieleman, H. Zen, K. Simonyan, O. Vinyals, A. Graves, N. Kalchbrenner, A. Senior, and K. Kavukcuoglu. WaveNet: A generative model for raw audio. ISCA Speech Synthesis Workshop , 2016.",
            "[28] D. P. Kingma and P. Dhariwal. Glow: Generative \ufb02ow with invertible 1 \u00d7 1 convolutions. Advances in Neural Information Processing Systems , 2018.",
            "[21] E. Hoogeboom, R. van den Berg, and M. Welling. Emerging convolutions for generative normalizing \ufb02ows. International Conference on Machine Learning , 2019.",
            "[26] S. Kim, S.-g. Lee, J. Song, and S. Yoon. FloWaveNet: A generative \ufb02ow for raw audio. arXiv:1811.02155 , 2018.",
            "[3] R. T. Q. Chen, Y. Rubanova, J. Bettencourt, and D. K. Duvenaud. Neural ordinary differential equations. Advances in Neural Information Processing Systems , 2018.",
            "[35] I. Loshchilov and F. Hutter. SGDR: Stochastic gradient descent with warm restarts. International Conference on Learning Representations , 2017.",
            "[24] S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. International Conference on Machine Learning , 2015.",
            "[59] A. van den Oord, N. Kalchbrenner, L. Espeholt, K. Kavukcuoglu, O. Vinyals, and A. Graves. Conditional image generation with PixelCNN decoders. Advances in Neural Information Processing Systems , 2016.",
            "[48] D. J. Rezende, S. Mohamed, and D. Wierstra. Stochastic backpropagation and approximate inference in deep generative models. International Conference on Machine Learning , 2014.",
            "[43] G. Papamakarios, T. Pavlakou, and I. Murray. Masked autoregressive \ufb02ow for density estimation. Advances in Neural Information Processing Systems , 2017.",
            "Table 2: Variational autoencoder test-set results (in nats) for the evidence lower bound (ELBO) and importance-weighted estimate of the log likelihood (computed as by Burda et al. [2] using 1000 importance samples). Error bars correspond to two standard deviations.",
            "[37] M. MacKay, P. Vicol, J. Ba, and R. B. Grosse. Reversible recurrent neural networks. Advances in Neural Information Processing Systems , 2018.",
            "[51] H. Salman, P. Yadollahpour, T. Fletcher, and K. Batmanghelich. Deep diffeomorphic normalizing \ufb02ows. arXiv:1810.03256 , 2018.",
            "[34] G. Loaiza-Ganem, Y. Gao, and J. P. Cunningham. Maximum entropy \ufb02ow networks. International Conference on Learning Representations , 2017.",
            "[40] C. Nash and C. Durkan. Autoregressive energy machines. International Conference on Machine Learning , 2019.",
            "[27] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. International Conference on Learning Representations , 2014.",
            "[45] R. Prenger, R. Valle, and B. Catanzaro. WaveGlow: A \ufb02ow-based generative network for speech synthesis. arXiv:1811.00002 , 2018.",
            "B RQ Spline Inverse Knots",
            "[33] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE , 86(11):2278\u20132324, 1998.",
            "[7] D. Dheeru and E. Karra Taniskidou. UCI machine learning repository, 2017. URL http://archive. ics.uci.edu/ml .",
            "Table 3: Test-set bits per dimension (BPD, lower is better) and parameter count for CIFAR-10 and ImageNet64 models. Superscript \u22c6 indicates results are taken from the existing literature.",
            "[8] J. V. Dillon, I. Langmore, D. Tran, E. Brevdo, S. Vasudevan, D. Moore, B. Patton, A. Alemi, M. Hoffman, and R. A. Saurous. TensorFlow Distributions. arXiv preprint arXiv:1711.10604 , 2017.",
            "[12] G. Elidan. Copulas in machine learning. Copulae in Mathematical and Quantitative Finance , 2013.",
            "[15] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Generative adversarial nets. Advances in Neural Information Processing Systems , 2014.",
            "[30] D. P. Kingma, T. Salimans, R. Jozefowicz, X. Chen, I. Sutskever, and M. Welling. Improved variational inference with inverse autoregressive \ufb02ow. Advances in Neural Information Processing Systems , 2016.",
            "[11] C. Durkan, A. Bekasov, I. Murray, and G. Papamakarios. Cubic-spline \ufb02ows. Workshop on Invertible Neural Networks and Normalizing Flows, International Conference on Machine Learning , 2019.",
            "[5] G. Cohen, S. Afshar, J. Tapson, and A. van Schaik. EMNIST: an extension of MNIST to handwritten letters. arXiv:1702.05373 , 2017.",
            "[39] T. M\u00fcller, B. McWilliams, F. Rousselle, M. Gross, and J. Nov\u00e1k. Neural importance sampling. arXiv:1808.03856 , 2018.",
            "[10] L. Dinh, J. Sohl-Dickstein, and S. Bengio. Density estimation using Real NVP. International Conference on Learning Representations , 2017.",
            "[50] T. Salimans, A. Karpathy, X. Chen, and D. P. Kingma. PixelCNN++: Improving the PixelCNN with discretized logistic mixture likelihood and other modi\ufb01cations. International Conference on Learning Representations , 2017.",
            "[55] J. M. Tomczak and M. Welling. Improving variational auto-encoders using Householder \ufb02ow. arXiv:1611.09630 , 2016.",
            "[31] A. Krizhevsky and G. Hinton. Learning multiple layers of features from tiny images. Master\u2019s thesis, Department of Computer Science, University of Toronto , 2009.",
            "[56] B. Uria, I. Murray, and H. Larochelle. RNADE: The real-valued neural autoregressive density-estimator. Advances in Neural Information Processing Systems , 2013.",
            "[25] P. Jaini, K. A. Selby, and Y. Yu. Sum-of-squares polynomial \ufb02ow. International Conference on Machine Learning , 2019.",
            "[17] J. Gregory and R. Delbourgo. Piecewise rational quadratic interpolation to monotonic data. IMA Journal of Numerical Analysis , 2(2):123\u2013130, 1982.",
            "[23] M. F. Hutchinson. A stochastic estimator of the trace of the in\ufb02uence matrix for Laplacian smoothing splines. Communications in Statistics - Simulation and Computation , 19(2):433\u2013450, 1990.",
            "[38] D. Martin, C. Fowlkes, D. Tal, and J. Malik. A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics. International Conference on Computer Vision , 2001.",
            "[46] D. J. Rezende and S. Mohamed. Variational inference with normalizing \ufb02ows. International Conference on Machine Learning , 2015.",
            "Training data Flow density Flow samples",
            "[61] Z. M. Ziegler and A. M. Rush. Latent normalizing \ufb02ows for discrete sequences. arXiv:1901.10548 , 2019.",
            "[6] N. De Cao, I. Titov, and W. Aziz. Block neural autoregressive \ufb02ow. Conference on Uncertainty in Arti\ufb01cial Intelligence , 2019.",
            "[18] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. IEEE Conference on Computer Vision and Pattern Recognition , 2016.",
            "[49] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and L. Fei-Fei. ImageNet large scale visual recognition challenge. International Journal of Computer Vision , 115(3):211\u2013252, 2015.",
            "[32] M. Kumar, M. Babaeizadeh, D. Erhan, C. Finn, S. Levine, L. Dinh, and D. Kingma. VideoFlow: A \ufb02ow-based generative model for video. arXiv:1903.01434 , 2019.",
            "[36] C. Louizos and M. Welling. Multiplicative normalizing \ufb02ows for variational Bayesian neural networks. International Conference on Machine Learning , 2017.",
            "[1] J. F. Blinn. How to solve a cubic equation, part 5: Back to numerics. IEEE Computer Graphics and Applications , 27(3):78\u201389, 2007.",
            "[14] A. N. Gomez, M. Ren, R. Urtasun, and R. B. Grosse. The reversible residual network: Backpropagation without storing activations. Advances in Neural Information Processing Systems , 2017.",
            "[54] M. Steffen. A simple method for monotonic interpolation in one dimension. Astronomy and Astrophysics , 239:443, 1990.",
            "[57] R. van den Berg, L. Hasenclever, J. M. Tomczak, and M. Welling. Sylvester normalizing \ufb02ows for variational inference. Conference on Uncertainty in Arti\ufb01cial Intelligence , 2018.",
            "[9] L. Dinh, D. Krueger, and Y. Bengio. NICE: Non-linear independent components estimation. International Conference on Learning Representations, Workshop track , 2015."
        ]
    }
}