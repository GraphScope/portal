{
    "data": {
        "id": "2001.11785v2",
        "published": "2020-02-04T01:38:42+00:00",
        "year": 2020,
        "month": 2,
        "title": "A Deep Reinforcement Learning Approach to Concurrent Bilateral Negotiation",
        "authors": [
            "Pallavi Bagga",
            "Nicola Paoletti",
            "Bedour Alrayes",
            "Kostas Stathis"
        ],
        "summary": "We present a novel negotiation model that allows an agent to learn how to negotiate during concurrent bilateral negotiations in unknown and dynamic e-markets. The agent uses an actor-critic architecture with model-free reinforcement learning to learn a strategy expressed as a deep neural network. We pre-train the strategy by supervision from synthetic market data, thereby decreasing the exploration time required for learning during negotiation. As a result, we can build automated agents for concurrent negotiations that can adapt to different e-market settings without the need to be pre-programmed. Our experimental evaluation shows that our deep reinforcement learning-based agents outperform two existing well-known negotiation strategies in one-to-many concurrent bilateral negotiations for a range of e-market settings.",
        "journal_ref": null,
        "doi": null,
        "primary_category": "cs.MA",
        "categories": [
            "cs.MA",
            "cs.AI"
        ],
        "bib": "@article{2001.11785v2,\\nAuthor        = {Pallavi Bagga and Nicola Paoletti and Bedour Alrayes and Kostas Stathis},\\nTitle         = {A Deep Reinforcement Learning Approach to Concurrent Bilateral Negotiation},\\nEprint        = {http://arxiv.org/abs/2001.11785v2},\\nArchivePrefix = {arXiv},\\nPrimaryClass  = {cs.MA},\\nAbstract      = {We present a novel negotiation model that allows an agent to learn how to\\nnegotiate during concurrent bilateral negotiations in unknown and dynamic\\ne-markets. The agent uses an actor-critic architecture with model-free\\nreinforcement learning to learn a strategy expressed as a deep neural network.\\nWe pre-train the strategy by supervision from synthetic market data, thereby\\ndecreasing the exploration time required for learning during negotiation. As a\\nresult, we can build automated agents for concurrent negotiations that can\\nadapt to different e-market settings without the need to be pre-programmed. Our\\nexperimental evaluation shows that our deep reinforcement learning-based agents\\noutperform two existing well-known negotiation strategies in one-to-many\\nconcurrent bilateral negotiations for a range of e-market settings.},\\nYear          = {2020},\\nMonth         = {1},\\nUrl           = {http://arxiv.org/pdf/2001.11785v2},\\nFile          = {2001.11785v2.pdf}\\n}",
        "reference": [
            "[An et al. , 2006] Bo An, Kwang Mong Sim, Liang Gui Tang, Shuang Qing Li, and Dai Jie Cheng. Continuous-time ne- gotiation mechanism for software agents. IEEE Transac- tions on Systems, Man, and Cybernetics, Part B (Cyber- netics) , 36(6):1261\u20131272, 2006.",
            "[Hindriks and Tykhonov, 2008] Koen Hindriks and Dmytro Tykhonov. Opponent modelling in automated multi-issue negotiation using bayesian learning. In Proceedings of the 7th international joint conference on Autonomous agents and multiagent systems-Volume 1 , pages 331\u2013338. Interna-",
            "[Oliver, 1996] Jim R Oliver. A machine-learning approach to automated negotiation and prospects for electronic com- merce. Journal of management information systems , 13(3):83\u2013112, 1996.",
            "[Bakker et al. , 2019] Jasper Bakker, Aron Hammond, Daan Bloembergen, and Tim Baarslag. Rlboa: A modular re- inforcement learning framework for autonomous negotiat- ing agents. In Proceedings of the 18th International Con- ference on Autonomous Agents and MultiAgent Systems ,",
            "[Baarslag et al. , 2016] Tim Baarslag, Mark JC Hendrikx, Koen V Hindriks, and Catholijn M Jonker. Learning",
            "machine learning perspective, deriving f c corresponds to a classi\ufb01cation problem, deriving f r to a regression problem.",
            "action it performs in the environment instead of at the end of the negotiation.",
            "[Choudhary and Bharadwaj, 2018] Nirmal Choudhary and KK Bharadwaj. Evolutionary learning approach to multi- agent negotiation for group recommender systems. Multi- media Tools and Applications , pages 1\u201323, 2018.",
            "[Rubinstein, 1982] Ariel Rubinstein. Perfect equilibrium in a bargaining model. Econometrica: Journal of the Econo- metric Society , pages 97\u2013109, 1982.",
            "[Faratin et al. , 1998] Peyman Faratin, Carles Sierra, and Nick R Jennings. Negotiation decision functions for au- tonomous agents. Robotics and Autonomous Systems , 24(3-4):159\u2013182, 1998.",
            "[Lewis et al. , 2017] Mike Lewis, Denis Yarats, Yann N Dauphin, Devi Parikh, and Dhruv Batra. Deal or no deal? end-to-end learning for negotiation dialogues. arXiv preprint arXiv:1706.05125 , 2017.",
            "[Nguyen and Jennings, 2004] Thuc Duong Nguyen and Nicholas R Jennings. Coordinating multiple concurrent negotiations. In Proceedings of the Third International",
            "[Goodfellow et al. , 2016] Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep learning . MIT press, 2016.",
            "[Zou et al. , 2014] Yi Zou, Wenjie Zhan, and Yuan Shao. Evolution with reinforcement learning in negotiation.",
            "[Zeng and Sycara, 1998] Dajun Zeng and Katia Sycara. Bayesian learning in negotiation. International Journal of Human-Computer Studies , 48(1):125\u2013141, 1998.",
            "[Williams et al. , 2012] Colin R Williams, Valentin Robu, Enrico H Gerding, and Nicholas R Jennings. Negotiating concurrently with unknown opponents in complex, real- time domains. 2012.",
            "[Papangelis and Georgila, 2015] Alexandros Papangelis and Kallirroi Georgila. Reinforcement learning of multi-issue negotiation dialogue policies. In Proceedings of the 16th Annual Meeting of the Special Interest Group on Dis- course and Dialogue , pages 154\u2013158, 2015.",
            "[Lee Rodgers and Nicewander, 1988] Joseph Lee Rodgers and W Alan Nicewander. Thirteen ways to look at the cor- relation coef\ufb01cient. The American Statistician , 42(1):59\u2013 66, 1988."
        ]
    }
}