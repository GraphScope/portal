**************QUERY***************: 
 
You are a highly skilled academic AI assistant. Your role is to respond to user queries with structured,
clear, and well-organized answers, maintaining an academic tone and focusing on relevance and clarity.

User Query: **Question**: List all contributions of the paper. These contributions are always organized and listed with a head sentence like **our contributions are as follows**. For each contribution, output the **original representation** and use a few words to summarize it.

Guidance:
Research papers typically contain key components, including the problem definition, challenges,
contributions, solutions, and experimental results. These components are generally organized as follows:
- **Problem Definition, Challenges, and Contributions**: Usually found within the first few sections.
- **Solutions**: Typically located in the main body of the paper.
- **Experiment Results**: Usually appear toward the end in sections titled "Experiments" or "Empirical Studies."

The content is retrieved in annotated chunks, marked with **SECTION_X** (indicating the specific section)
or **POS_0.XX** (indicating the position within the paper, calculated as current page/total pages).
Use these annotations to identify and focus on the sections most relevant to the userâ€™s query,
ensuring a precise and targeted response.
                             **************MEMORY**************: 
 **SECTION_1**: amples. To overcome the lack of real world negotiation data for the initial training, we generate synthetic datasets using the simulation environment in Alrayes et al., 2016 and two well known strategies for concurrent bilateral negotiation described in Alrayes et al., 2018 and Williams et al., 2012 respectively. With this work, we empirically demonstrate three important bene ts of our deep learning framework for automated negotiations: 1 existing negotiation strategies can be accu
**SECTION_1**: against its opponents which use xed but unknown strategies during concurrent negotiations in an environment with incomplete information. We choose deep neural networks as they provide a rich class of strategy functions to capture the complex decisions making behind negotiation. Since RL approaches need a long time to nd an optimal policy from scratch we pre train our deep negotiation strategies using supervised learning SL from a set of training ex
**SECTION_paper_meta**: A Deep Reinforcement Learning Approach to Concurrent Bilateral Negotiation Pallavi Bagga1 , Nicola Paoletti2 , Bedour Alrayes3 and Kostas Stathis4 1,2,4Royal Holloway, University of London 3King Saud University, Saudi Arabia pallavi.bagga.20171, nicola.paoletti2, kostas.stathis4 rhul.ac.uk, balrayes ksu.edu.sa3
**SECTION_1**: rately approximated using neural networks; 2 evolving a pretrained strategy using DRL with additional negotiation experience yields strategies that even outperform the teachers, i.e., the strategies used for supervision; 3 buyer strategies trained assuming a particular seller strategy quickly adapt via DRL to different and unknown sellers behaviours. In summary, our contribution is threefold: we propose a novel agent model for one to many concurrent bilateral nego
**SECTION_1**: tions are managed in such strategies through a coordinator agent Rahwan et al., 2002 or by coordinating multiple dialogues internally Alrayes and Stathis, 2013 , but do not support agent learning which is our main focus. Other approaches use agent learning based on Genetic Algorithms GA Oliver, 1996; Zou et al., 2014 , but they require a huge number of trials before obtaining a good strategy, which makes them infeasible for online negotiation settings. Rein
**SECTION_1**: tiations based on DRL and SL; we extend the existing simulation environment Alrayes et al., 2016 to generate data and perform experiments that support agent learning for negotiation; and we run an extensive experiments showing that our approach outperforms the existing strategies and produces adaptable agents that can transfer to a range of e market settings.
**SECTION_1**: forcement Learning RL based negotiation approaches typically employ Q learning Papangelis and Georgila, 2015; Bakker et al., 2019; Rodriguez Fernandez et al., 2019 which does not support continuous actions. This is an important limitation in our setting because we want the agent to learn how much to concede e.g. on the price of an item for sale, which in turn naturally leads to a continuous action space. Consequently, the design of autonomous agents capable of learning
**SECTION_1**: 1https: www.ebay.com a strategy from concurrent negotiations with other agents is still an important open problem. We propose, to the best of our knowledge, the rst Deep Reinforcement Learning DRL approach for one to many concurrent bilateral negotiations in open, dynamic and unknown e market settings. In particular, we de ne a novel DRL inspired agent model called ANEGMA, which allows the buyer to develop an adaptive strategy to effectively use
**SECTION_abstract**: Abstract We present a novel negotiation model that allows an agent to learn how to negotiate during concurrent bilateral negotiations in unknown and dynamic e markets. The agent uses an actor critic architecture with model free reinforcement learning to learn a strategy expressed as a deep neural network. We pre train the strategy by supervision from synthetic market data, thereby decreasing the exploration time required for learning during
**SECTION_abstract**: negotiation. As a result, we can build automated agents for concurrent negotiations that can adapt to different e market settings without the need to be pre programmed. Our experimental evaluation shows that our deep reinforcement learning based agents outperform two existing well known negotiation strategies in one to many concurrent bilateral negotiations for a range of e market settings.
**SECTION_1**: 1 Introduction We are concerned with the problem of learning a strategy for a buyer agent to engage in concurrent bilateral negotiations with unknown seller agents in open and dynamic e markets such as E bay1. Previous work in concurrent bilateral negotiation has mainly focused on heuristic strategies Nguyen and Jennings, 2004; Mansour and Kowalczyk, 2014; An et al., 2006 , some of which adapt to changes in the environment Williams et al., 2012 . Different bilateral negotia
