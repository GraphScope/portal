{
    "data": {
        "id": "2407.00567v1",
        "published": "2024-07-02T13:37:10+00:00",
        "year": 2024,
        "month": 7,
        "title": "A Contextual Combinatorial Bandit Approach to Negotiation",
        "authors": [
            "Yexin Li",
            "Zhancun Mu",
            "Siyuan Qi"
        ],
        "summary": "Learning effective negotiation strategies poses two key challenges: the exploration-exploitation dilemma and dealing with large action spaces. However, there is an absence of learning-based approaches that effectively address these challenges in negotiation. This paper introduces a comprehensive formulation to tackle various negotiation problems. Our approach leverages contextual combinatorial multi-armed bandits, with the bandits resolving the exploration-exploitation dilemma, and the combinatorial nature handles large action spaces. Building upon this formulation, we introduce NegUCB, a novel method that also handles common issues such as partial observations and complex reward functions in negotiation. NegUCB is contextual and tailored for full-bandit feedback without constraints on the reward functions. Under mild assumptions, it ensures a sub-linear regret upper bound. Experiments conducted on three negotiation tasks demonstrate the superiority of our approach.",
        "journal_ref": null,
        "doi": null,
        "primary_category": "cs.AI",
        "categories": [
            "cs.AI",
            "cs.LG"
        ],
        "bib": "@article{2407.00567v1,\\nAuthor        = {Yexin Li and Zhancun Mu and Siyuan Qi},\\nTitle         = {A Contextual Combinatorial Bandit Approach to Negotiation},\\nEprint        = {http://arxiv.org/abs/2407.00567v1},\\nArchivePrefix = {arXiv},\\nPrimaryClass  = {cs.AI},\\nAbstract      = {Learning effective negotiation strategies poses two key challenges: the\\nexploration-exploitation dilemma and dealing with large action spaces. However,\\nthere is an absence of learning-based approaches that effectively address these\\nchallenges in negotiation. This paper introduces a comprehensive formulation to\\ntackle various negotiation problems. Our approach leverages contextual\\ncombinatorial multi-armed bandits, with the bandits resolving the\\nexploration-exploitation dilemma, and the combinatorial nature handles large\\naction spaces. Building upon this formulation, we introduce NegUCB, a novel\\nmethod that also handles common issues such as partial observations and complex\\nreward functions in negotiation. NegUCB is contextual and tailored for\\nfull-bandit feedback without constraints on the reward functions. Under mild\\nassumptions, it ensures a sub-linear regret upper bound. Experiments conducted\\non three negotiation tasks demonstrate the superiority of our approach.},\\nYear          = {2024},\\nMonth         = {6},\\nUrl           = {http://arxiv.org/pdf/2407.00567v1},\\nFile          = {2407.00567v1.pdf}\\n}",
        "reference": [
            "",
            "Paquette, P., Lu, Y., Bocco, S., Smith, M. O., O-G, S., Kummerfeld, J. K., Singh, S., Pineau, J., and Courville, A. No-press diplomacy: Modeling multi-agent gameplay.",
            "Conference on Data Mining , pp. 461\u2013469, 2014. Rejwan, I. and Mansour, Y. Top-k combinatorial bandits with full-bandit feedback. In Proceedings of the 31st In- ternational Conference on Algorithmic Learning Theory , pp. 752\u2013776. PMLR, 2020.",
            "Nie, G., Agarwal, M., Umrawal, A. K., Aggarwal, V., and Quinn, C. J. An explore-then-commit algorithm for sub- modular maximization under full-bandit feedback. In Proceedings of the 38th Conference on Uncertainty in Artificial Intelligence , pp. 1541\u20131551. PMLR, 2022.",
            "Liu, B., Wei, Y., Zhang, Y., Yan, Z., and Yang, Q. Transfer- able contextual bandit for cross-domain recommendation.",
            "Bakker, J., Hammond, A., Bloembergen, D., and Baarslag, T. Rlboa: A modular reinforcement learning framework for autonomous negotiating agents. In Proceedings of the 18th International Conference on Autonomous Agents and Multiagent Systems , pp. 260\u2013268, 2019.",
            "Buron, C. L. R., Guessoum, Z., and Ductor, S. Mcts-based automated negotiation agent. In Proceedings of the 22nd International Conference on Principles and Practice of Multi-Agent System , 2019.",
            "Quinn, C. J. An explore-then-commit algorithm for sub- modular maximization under full-bandit feedback. In Proceedings of the 38th Conference on Uncertainty in Artificial Intelligence , pp. 1541\u20131551. PMLR, 2022.",
            "Yang, Y., and Zhu, S. Civrealm: A learning and reasoning odyssey in civilization for decision-making agents. In Proceedings of the 12nd International Conference on Learning Representations , 2024.",
            "Li, L., Chu, W., Langford, J., and Schapire, R. E. A contextual-bandit approach to personalized news arti- cle recommendation. In Proceedings of the 19th Inter- national Conference on World Wide Web , pp. 661\u2013670, 2010.",
            "S. L., and Hassabis, D. Human-level control through deep reinforcement learning. nature , pp. 529\u2013533, 2015.",
            "those fall in the reinforcement learning paradigm, the model presented in this work may be limited due to the lack of an explicitly given negotiation target.",
            "Agarwal, M., Aggarwal, V., Umrawal, A. K., and Quinn, C. Dart: Adaptive accept reject algorithm for non-linear combinatorial bandits. In Proceedings of the 35th AAAI Conference on Artificial Intelligence , pp. 6557\u20136565, 2021.",
            "In Advances in Neural Information Processing Systems , 2019.",
            "Acknowledgements This work was supported by the National Natural Science Foundation of China.",
            "Aydogan, R., Baarslag, T., Fujita, K., Hoos, H. H., Jonker, C. M., Mohammad, Y., and Renting, B. M. The 13th international automated negotiating agent competition challenges and results. Technical report, In International Joint Conference on Artificial Intelligence, 2023.",
            "2010. Liu, B., Wei, Y., Zhang, Y., Yan, Z., and Yang, Q. Transfer- able contextual bandit for cross-domain recommendation.",
            "Bhatnagar, S., Sutton, R. S., Ghavamzadeh, M., and Lee, M. Natural actor\u2013critic algorithms. Automatica , 45(11): 2471\u20132482, 2009.",
            "Bagga, P., Paoletti, N., Alrayes, B., and Stathis, K. A deep reinforcement learning approach to concurrent bilateral negotiation. In Proceedings of the 29th International Joint Conference on Artificial Intelligence , pp. 297\u2013303, 2020.",
            "2021. Aydogan, R., Baarslag, T., Fujita, K., Hoos, H. H., Jonker, C. M., Mohammad, Y., and Renting, B. M. The 13th international automated negotiating agent competition challenges and results. Technical report, In International",
            "Rejwan, I. and Mansour, Y. Top-k combinatorial bandits with full-bandit feedback. In Proceedings of the 31st In- ternational Conference on Algorithmic Learning Theory , pp. 752\u2013776. PMLR, 2020.",
            "Impact Statement This paper aims to advance the field of negotiation among agents with diverse interests from a multi-armed bandit per- spective, which is well-suited for negotiation problems and has been well-investigated. It encourages future research to tackle any limitation of our method under the general formu-",
            "has been well-investigated. It encourages future research to tackle any limitation of our method under the general formu- lation utilizing the advantages of bandit-based techniques.",
            "References Agarwal, M., Aggarwal, V., Umrawal, A. K., and Quinn, C. Dart: Adaptive accept reject algorithm for non-linear combinatorial bandits. In Proceedings of the 35th AAAI Conference on Artificial Intelligence , pp. 6557\u20136565, 2021.",
            "Intelligence , 2018. Liu, T. and Zheng, Z. Negotiation assistant bot of pric- ing prediction based on machine learning. International Journal of Intelligence Science , 10(02), 2020.",
            "Liu, T. and Zheng, Z. Negotiation assistant bot of pric- ing prediction based on machine learning. International Journal of Intelligence Science , 10(02), 2020.",
            "Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A. A., Veness, J., Bellemare, M. G., Graves, A., Riedmiller, M., Fidje- land, A. K., Ostrovski, G., Petersen, S., Beattie, C., Sadik, A., Antonoglou, I., King, H., Kumaran, D., D. Wierstra1, S. L., and Hassabis, D. Human-level control through deep",
            "at each time step, which is a very mild constraint in nego- tiation . However, for tasks where hypermetropic planning plays the main role and negotiation is only one type of ac- tion that merely assists the agent in completing the task, i.e., those fall in the reinforcement learning paradigm, the model presented in this work may be limited due to the lack of an",
            "Qi, S., Chen, S., Li, Y., Kong, X., Wang, J., Yang, B., Wong, P., Zhong, Y., Zhang, X., Zhang, Z., Liu, N., Wang, W., Yang, Y., and Zhu, S. Civrealm: A learning and reasoning odyssey in civilization for decision-making agents. In Proceedings of the 12nd International Conference on",
            "Figure 7. A case of negotiation in CivRealm. Thailand is our nego- tiator, while Portugal is our counterpart.",
            "Qin, L., Chen, S., and Zhu, X. Contextual combinatorial bandit and its application on diversified online recommen- dation. In Proceedings of the 2014 SIAM International Conference on Data Mining , pp. 461\u2013469, 2014."
        ]
    }
}